import google.generativeai as genai
from google.generativeai.types import Tool, FunctionDeclaration
from config import MODEL_NAME, SYSTEM_INSTRUCTION, TABLES_CONFIG
import re
import json
import pandas as pd
import plotly.express as px
from utils import create_styled_download_button, generate_excel_bytes, generate_csv_bytes
from datetime import datetime

def initialize_model():
    """
    Inicializa o modelo Gemini com instru√ß√µes din√¢micas baseadas nas tabelas configuradas
    """
    
    # Constr√≥i a descri√ß√£o dinamicamente baseada nas tabelas dispon√≠veis
    tables_description = "Consulta dados no BigQuery. Tabelas dispon√≠veis:\n"
    for table_name, config in TABLES_CONFIG.items():
        tables_description += f"- {table_name}: {config['description']}\n"
    
    tables_description += (
        "\nREGRAS ABSOLUTAS:\n"
        "1. Para TOP N por grupo (ex: top 3 por estado) USE QUALIFY com PARTITION BY\n"
        "2. NUNCA use LIMIT para consultas agrupadas\n"
        "3. Para m√∫ltiplas dimens√µes inclua TODOS os campos do PARTITION BY no SELECT\n"
        "4. Campos no GROUP BY DEVEM estar no SELECT\n"
        "5. SEMPRE use a tabela correta baseada na pergunta do usu√°rio\n\n"
        "Exemplo CORRETO para top 3 modelos por estado:\n"
        "{\n"
        '  "table_name": "drvy_VeiculosVendas",\n'
        '  "select": ["modelo", "uf", "SUM(QTE) AS total"],\n'
        '  "where": "EXTRACT(YEAR FROM dta_venda) = 2024",\n'
        '  "group_by": ["modelo", "uf"],\n'
        '  "order_by": ["uf", "total DESC"],\n'
        '  "qualify": "ROW_NUMBER() OVER (PARTITION BY uf ORDER BY total DESC) <= 3"\n'
        "}"
    )
    
    query_func = FunctionDeclaration(
        name="query_business_data",
        description=tables_description,
        parameters={
            "type": "object",
            "properties": {
                "table_name": {
                    "type": "string",
                    "description": f"Nome da tabela no BigQuery. Op√ß√µes: {', '.join(TABLES_CONFIG.keys())}",
                    "enum": list(TABLES_CONFIG.keys())
                },
                "select": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Campos para SELECT (DEVE incluir todos do PARTITION BY)",
                },
                "where": {
                    "type": "string",
                    "description": "Condi√ß√µes WHERE (SQL puro)",
                },
                "group_by": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Campos para GROUP BY (DEVEM estar no SELECT)",
                },
                "order_by": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Campos para ORDER BY",
                },
                "qualify": {
                    "type": "string",
                    "description": "CONDI√á√ÉO OBRIGAT√ìRIA para TOP N: ROW_NUMBER() OVER (PARTITION BY...) <= N",
                },
                "limit": {
                    "type": "integer",
                    "description": "USO PROIBIDO para consultas agrupadas - apenas para consultas simples",
                },
            },
            "required": ["table_name", "select"],
        },
    )

    business_tool = Tool(function_declarations=[query_func])

    generation_config = {
        "temperature": 0.5,
        "max_output_tokens": 2000,
    }

    return genai.GenerativeModel(
        MODEL_NAME,
        tools=[business_tool],
        system_instruction=SYSTEM_INSTRUCTION,
        generation_config=generation_config,
    )


def generate_chart(data, chart_type, x_axis, y_axis, color=None):
    """Gera gr√°fico com tratamento para m√∫ltiplas dimens√µes"""
    if not data or not x_axis or not y_axis:
        return None

    try:
        df = pd.DataFrame.from_records(data)

        # Verifica√ß√£o de colunas com tratamento para m√∫ltiplas dimens√µes
        required_columns = {x_axis, y_axis}
        if color:  # Terceira dimens√£o
            required_columns.add(color)
            if color not in df.columns:
                color = None  # Degrada para 2D

        # Convers√£o segura de tipos para eixos
        df[y_axis] = pd.to_numeric(df[y_axis], errors="coerce")

        # Paleta de cores para m√∫ltiplas categorias
        palette = px.colors.qualitative.Plotly

        if chart_type == "bar":
            fig = px.bar(
                df,
                x=x_axis,
                y=y_axis,
                color=color,
                barmode="group",  # Essencial para m√∫ltiplas dimens√µes
                color_discrete_sequence=palette,
            )
        elif chart_type == "line":
            fig = px.line(
                df,
                x=x_axis,
                y=y_axis,
                color=color,
                markers=True,
                color_discrete_sequence=palette,
            )
        else:
            return None

        fig.update_layout(hovermode="x unified", plot_bgcolor="rgba(0,0,0,0)")
        return fig

    except Exception as e:
        print(f"Erro ao gerar gr√°fico (multi-dimens√£o): {str(e)}")
        return None


def refine_with_gemini(
    prompt: str, data: list, function_params: dict = None, query: str = None
):
    """
    Envia os dados para o Gemini fazer o refinamento e retorna a resposta e detalhes t√©cnicos.
    """
    if function_params is not None:
        if hasattr(function_params, "_values"):
            function_params = {k: v for k, v in function_params.items()}
        elif not isinstance(function_params, dict):
            function_params = dict(function_params)

    instruction = f"""
    Voc√™ √© um analista de dados especializado. Sua tarefa √©:
    1. Analisar os dados fornecidos (em JSON abaixo) + a pergunta do usu√°rio e gerar uma resposta completa e contextualizada.
    2. Responder √† pergunta do usu√°rio de forma completa.
    3. Formatar a resposta com:
       - Introdu√ß√£o contextual
       - Principais insights
       - Dados em formato tabular (quando aplic√°vel)
       - S√≥ gere gr√°ficos se e somente se for solicitado a gerar (usando formato GRAPH-TYPE)
       - S√≥ gere arquivos excel/xlsx ou csv se o usu√°rio solicitar explicitamente (usando palavras como exportar, baixar, excel, planilha, csv).
       - Aten√ß√£o √† formata√ß√£o para evitar erros de markdown.

    IMPORTANTE: Os dados fornecidos s√£o FINAIS e COMPLETOS. N√ÉO tente solicitar dados adicionais, 
    fazer compara√ß√µes com per√≠odos n√£o presentes nos dados, ou sugerir que faltam informa√ß√µes 
    se a pergunta pode ser respondida com os dados dispon√≠veis.

    PERGUNTA DO USU√ÅRIO: "{prompt}"

    DADOS PARA AN√ÅLISE:
    {json.dumps(data, indent=2, default=str)}

    FORMATO ESPERADO DA RESPOSTA:
    [Contexto e introdu√ß√£o]

    [An√°lise dos principais resultados]

    [Tabela ou resumo dos dados quando relevante]

    [Sugest√£o de gr√°fico se aplic√°vel, no formato:]
    GRAPH-TYPE: [tipo] | X-AXIS: [coluna] | Y-AXIS: [coluna] | COLOR: [coluna]
    - O tipo pode ser "bar" ou "line", nunca gere "pie". 
    - COLOR √© opcional e deve ser usado para representar a terceira dimens√£o.
    - As colunas devem existir nos dados fornecidos.

    [Exporta√ß√£o de dados se solicitado, no formato:]
    EXPORT-INFO: FORMATO: [excel/csv] 
    - Aqui voc√™ s√≥ precisa fornecer essa linha de EXPORT-INFO, n√£o fornecer nenhuma informa√ß√£o a mais sobre o arquivo.
    
    ATEN√á√ÉO: 
    S√≥ gere visualiza√ß√£o gr√°fica se o usu√°rio solicitar explicitamente um gr√°fico, visualiza√ß√£o, plot, curva, barra, linha ou termos semelhantes.
   - Nunca gere gr√°fico por padr√£o, nem sugira gr√°fico se n√£o for solicitado.
        Exemplo: 
        Usu√°rio: "Quais as vendas das lojas de limoeiro em janeiro/2025?"
        Resposta: [N√ÉO incluir gr√°fico]
        Usu√°rio: "Me mostre um gr√°fico das vendas das lojas de limoeiro em janeiro/2025"
        Resposta: [Incluir gr√°fico conforme instru√ß√£o]
        
    Se o usu√°rio solicitar exporta√ß√£o, gere links para download dos dados em Excel e CSV. 
    - Nunca gere se n√£o houver dados ou se n√£o for explicitamente solicitado.
    """

    model = genai.GenerativeModel(MODEL_NAME)
    response = model.generate_content(instruction)
    response_text = response.text
    chart_info = None

    # Extrai instru√ß√£o de gr√°fico, se houver
    if "GRAPH-TYPE:" in response_text:
        try:
            graph_part = response_text.split("GRAPH-TYPE:")[1].strip()
            graph_type = graph_part.split("|")[0].strip()
            x_axis = graph_part.split("X-AXIS:")[1].split("|")[0].strip()
            y_axis = graph_part.split("Y-AXIS:")[1].split("|")[0].strip()
            color = None
            if "COLOR:" in graph_part:
                color = graph_part.split("COLOR:")[1].strip()

            fig = generate_chart(data, graph_type, x_axis, y_axis, color)
            #print("DEBUG generate_chart:", fig)
            if fig:
                chart_info = {
                    "type": graph_type,
                    "x": x_axis,
                    "y": y_axis,
                    "color": color,
                    "fig": fig,
                }

            else:
                print(
                    "DEBUG gr√°fico n√£o gerado. Dados:",
                    data,
                    "Tipo:",
                    graph_type,
                    "X:",
                    x_axis,
                    "Y:",
                    y_axis,
                    "Color:",
                    color,
                )
                response_text = response_text.split("GRAPH-TYPE:")[0].strip()
        except Exception as e:
            print(f"Erro ao processar instru√ß√£o de gr√°fico: {e}")

    # Verificar se o usu√°rio solicitou exporta√ß√£o
    export_requested = any(keyword in prompt.lower() for keyword in 
                          ['exportar', 'excel', 'planilha', 'csv', 'baixar']) or "EXPORT:" in response_text
    
    # Gerar links de exporta√ß√£o se solicitado
    export_links = []
    export_info = {}
    
    if export_requested:
        # Gerar Excel
        excel_bytes = generate_excel_bytes(data)
        if excel_bytes:
            excel_filename = f"dados_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx"
            excel_link = create_styled_download_button(excel_bytes, excel_filename, "Excel")
            export_links.append(excel_link)
            export_info['excel'] = excel_filename
        
        # Gerar CSV
        csv_bytes = generate_csv_bytes(data)
        if csv_bytes:
            csv_filename = f"dados_{datetime.now().strftime('%Y%m%d_%H%M')}.csv"
            csv_link = create_styled_download_button(csv_bytes, csv_filename, "CSV")
            export_links.append(csv_link)
            export_info['csv'] = csv_filename

    tech_details = {
        "function_params": function_params,
        "query": query,
        "raw_data": data,
        "chart_info": chart_info,
        "export_links": export_links,
        "export_info": export_info,
    }
    #response_text = re.sub(r"GRAPH-TYPE:.*", "", response_text).strip()
    return response_text, tech_details


def should_reuse_data(model, current_prompt: str, last_data: dict, user_history: list = None) -> dict:
    """
    Pergunta ao Gemini se deve reutilizar os dados da √∫ltima consulta
    considerando o hist√≥rico do usu√°rio
    Retorna um dict com 'should_reuse': bool e 'reason': str
    """
    if not last_data.get("raw_data") or not last_data.get("prompt"):
        return {"should_reuse": False, "reason": "Nenhum dado anterior dispon√≠vel"}
    
    # Constr√≥i contexto do hist√≥rico recente (√∫ltimas 5 intera√ß√µes)
    history_context = ""
    if user_history:
        recent_history = user_history[-5:]  # √öltimas 5 intera√ß√µes
        history_items = []
        for interaction in recent_history:
            history_items.append(f"- {interaction.get('user_prompt', 'N/A')}")
        if history_items:
            history_context = f"\nHIST√ìRICO RECENTE:\n" + "\n".join(history_items) + "\n"
    
    context_prompt = f"""
Analise se a nova pergunta pode ser respondida REUTILIZANDO os dados da consulta anterior:
{history_context}
PERGUNTA ANTERIOR: "{last_data.get('prompt', '')}"
NOVA PERGUNTA: "{current_prompt}"

DADOS DISPON√çVEIS: {len(last_data.get('raw_data', []))} registros da √∫ltima consulta

üî¥ REGRA FUNDAMENTAL: SEJA EXTREMAMENTE CONSERVADOR na reutiliza√ß√£o!

‚úÖ REUTILIZAR APENAS nos casos √ìBVIOS de exporta√ß√£o/visualiza√ß√£o:
- "gerar excel", "exportar csv", "baixar planilha" dos MESMOS dados EXATOS
- "criar gr√°fico", "fazer visualiza√ß√£o" dos MESMOS dados EXATOS
- "mostrar em tabela", "formatar em HTML" dos MESMOS dados EXATOS
- Reformula√ß√£o simples da mesma resposta (sem mudan√ßa de dados)

‚ùå NUNCA REUTILIZAR quando houver QUALQUER tipo de:
- CONTAGEM: "conte", "contar", "quantos", "contagem" ‚Üí SQL COUNT()
- AGREGA√á√ÉO: "some", "total", "m√©dia", "m√°ximo", "m√≠nimo" ‚Üí SQL SUM(), AVG(), MAX(), MIN()
- AGRUPAMENTO: "por modelo", "por categoria", "por ano" ‚Üí SQL GROUP BY
- ORDENA√á√ÉO diferente: "mais vendidos", "ranking" ‚Üí SQL ORDER BY
- C√ÅLCULOS: "porcentagem", "percentual", "propor√ß√£o" ‚Üí SQL com c√°lculos
- FILTROS adicionais: "apenas Honda", "s√≥ 2024" ‚Üí SQL WHERE
- COMPARA√á√ïES: "compare", "versus", "diferen√ßa" ‚Üí SQL JOINS/UNION
- PER√çODOS diferentes: qualquer ano/m√™s/data diferente
- LOCAIS diferentes: qualquer estado/cidade/regi√£o diferente
- PRODUTOS/MODELOS diferentes ou espec√≠ficos
- Palavras como: "tamb√©m", "al√©m disso", "inclua", "mostre mais"
- Qualquer palavra que indica TRANSFORMA√á√ÉO dos dados

üö® CASOS CR√çTICOS QUE SEMPRE REQUEREM NOVA CONSULTA:
- "conte os modelos" ‚Üí SQL: SELECT modelo, COUNT(*) ... GROUP BY modelo
- "quantos por estado" ‚Üí SQL: SELECT estado, COUNT(*) ... GROUP BY estado  
- "total de vendas" ‚Üí SQL: SELECT SUM(quantidade) ...
- "modelos mais vendidos" ‚Üí SQL: ... ORDER BY vendas DESC
- "apenas Honda" ‚Üí SQL: ... WHERE marca = 'Honda'
- "dados de 2024" ‚Üí SQL: ... WHERE ano = 2024

LEMBRE-SE: O BigQuery √© MUITO mais eficiente para agrega√ß√µes/contagens/filtros 
do que tentar fazer isso localmente com os dados j√° retornados!

EXEMPLOS PR√ÅTICOS:
‚úÖ "gere um excel desses dados" ‚Üí REUTILIZAR (exporta√ß√£o)
‚ùå "conte os modelos" ‚Üí NOVA CONSULTA (COUNT + GROUP BY)
‚ùå "quantos Honda?" ‚Üí NOVA CONSULTA (COUNT + WHERE)
‚ùå "mais vendidos primeiro" ‚Üí NOVA CONSULTA (ORDER BY)
‚ùå "total geral" ‚Üí NOVA CONSULTA (SUM)

Responda APENAS no formato JSON v√°lido:
{{"should_reuse": true, "reason": "explica√ß√£o clara"}}
ou
{{"should_reuse": false, "reason": "explica√ß√£o clara"}}
"""

    try:
        # Usa um modelo simples s√≥ para avalia√ß√£o, sem tools
        evaluation_model = genai.GenerativeModel(
            MODEL_NAME,
            generation_config={"temperature": 0.0, "max_output_tokens": 200}  # Mais tokens para processar instru√ß√µes complexas
        )
        
        response = evaluation_model.generate_content(context_prompt)
        response_text = response.text.strip()
        
        # Tenta extrair JSON da resposta
        if "{" in response_text and "}" in response_text:
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1
            json_str = response_text[json_start:json_end]
            result = json.loads(json_str)
            return result
        else:
            return {"should_reuse": False, "reason": "Resposta inv√°lida do modelo"}
            
    except Exception as e:
        print(f"Erro na avalia√ß√£o de reutiliza√ß√£o: {str(e)}")
        # Em caso de erro, n√£o reutiliza por seguran√ßa
        return {"should_reuse": False, "reason": f"Erro na avalia√ß√£o: {str(e)}"}
